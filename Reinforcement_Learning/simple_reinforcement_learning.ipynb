{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkWlRFoi+DP19VokfTqOsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkarshAnilkumar/Machine_Learning/blob/main/Reinforcement_Learning/simple_reinforcement_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simple Reinforcement Program**"
      ],
      "metadata": {
        "id": "A2TL2_TeeVLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple program that contains the basic structure of how Environment and Agent should be implemented and in this program decisions *are not taken* based on current state.\n",
        "Here Agent's goal is to accumulate the reward not maximize it.\n"
      ],
      "metadata": {
        "id": "OFOwRpyb6g8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6O6h61JseUXh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# from typing import list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class sample_environment:\n",
        "  def __init__(self):\n",
        "    self.steps_left = 20\n",
        "  def get_observations(self):\n",
        "    return ([0.0,0.0,0.0])\n",
        "  def get_actions(self):\n",
        "    return [0,1]\n",
        "  def is_done(self):\n",
        "    return self.steps_left == 0\n",
        "  def actions(self,action):\n",
        "    if self.is_done():\n",
        "      raise Exception(\"Game over\")\n",
        "    self.steps_left -= 1\n",
        "    return random.random()"
      ],
      "metadata": {
        "id": "7MevvISgeiuA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class agent:\n",
        "  def __init__(self):\n",
        "    self.current_reward = 0\n",
        "  def step(self,env):\n",
        "    # obsv = env.get_observations()\n",
        "    # print(obsv)\n",
        "    actions = env.get_actions()\n",
        "    print(\"Action chosen\", random.choice(actions))\n",
        "    reward = env.actions(random.choice(actions))\n",
        "    print(reward)\n",
        "    self.current_reward += reward\n",
        "    print(f\"Total Reward = \",self.current_reward)\n"
      ],
      "metadata": {
        "id": "dkXKETBMG9Q2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  env = sample_environment()\n",
        "  agt = agent()\n",
        "\n",
        "  i = 0\n",
        "  while not env.is_done():\n",
        "    i = i+1\n",
        "    print(f\"Step {i+1}, observations = {env.get_observations()}, actions = {env.get_actions()} reward = {agt.current_reward}\")\n",
        "    agt.step(env)\n",
        "  # print(f\"Total reward = {agt.current_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWqmR6IUIBQ6",
        "outputId": "de6e0a3c-5cab-4669-d22d-a26dba4c293c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 0\n",
            "Action chosen 0\n",
            "0.3573107634425299\n",
            "Total Reward =  0.3573107634425299\n",
            "Step 3, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 0.3573107634425299\n",
            "Action chosen 0\n",
            "0.6057557529498473\n",
            "Total Reward =  0.9630665163923772\n",
            "Step 4, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 0.9630665163923772\n",
            "Action chosen 1\n",
            "0.8884674264304712\n",
            "Total Reward =  1.8515339428228483\n",
            "Step 5, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 1.8515339428228483\n",
            "Action chosen 0\n",
            "0.980635639970082\n",
            "Total Reward =  2.8321695827929303\n",
            "Step 6, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 2.8321695827929303\n",
            "Action chosen 0\n",
            "0.9251039474495131\n",
            "Total Reward =  3.7572735302424434\n",
            "Step 7, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 3.7572735302424434\n",
            "Action chosen 1\n",
            "0.1493011743966417\n",
            "Total Reward =  3.906574704639085\n",
            "Step 8, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 3.906574704639085\n",
            "Action chosen 0\n",
            "0.7429838833834859\n",
            "Total Reward =  4.649558588022571\n",
            "Step 9, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 4.649558588022571\n",
            "Action chosen 1\n",
            "0.27231370408632305\n",
            "Total Reward =  4.921872292108894\n",
            "Step 10, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 4.921872292108894\n",
            "Action chosen 1\n",
            "0.3434557514034655\n",
            "Total Reward =  5.265328043512359\n",
            "Step 11, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 5.265328043512359\n",
            "Action chosen 1\n",
            "0.7823778149093935\n",
            "Total Reward =  6.047705858421753\n",
            "Step 12, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 6.047705858421753\n",
            "Action chosen 1\n",
            "0.30504771144419296\n",
            "Total Reward =  6.352753569865946\n",
            "Step 13, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 6.352753569865946\n",
            "Action chosen 1\n",
            "0.5070088572199096\n",
            "Total Reward =  6.859762427085856\n",
            "Step 14, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 6.859762427085856\n",
            "Action chosen 1\n",
            "0.8437414887858282\n",
            "Total Reward =  7.703503915871685\n",
            "Step 15, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 7.703503915871685\n",
            "Action chosen 0\n",
            "0.7070341194298337\n",
            "Total Reward =  8.410538035301519\n",
            "Step 16, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 8.410538035301519\n",
            "Action chosen 0\n",
            "0.5304147000226147\n",
            "Total Reward =  8.940952735324133\n",
            "Step 17, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 8.940952735324133\n",
            "Action chosen 0\n",
            "0.5247249908970267\n",
            "Total Reward =  9.46567772622116\n",
            "Step 18, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 9.46567772622116\n",
            "Action chosen 1\n",
            "0.08434739181723605\n",
            "Total Reward =  9.550025118038397\n",
            "Step 19, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 9.550025118038397\n",
            "Action chosen 0\n",
            "0.9198280631768736\n",
            "Total Reward =  10.46985318121527\n",
            "Step 20, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 10.46985318121527\n",
            "Action chosen 1\n",
            "0.9068668091031079\n",
            "Total Reward =  11.376719990318378\n",
            "Step 21, observations = [0.0, 0.0, 0.0], actions = [0, 1] reward = 11.376719990318378\n",
            "Action chosen 0\n",
            "0.4456379648355775\n",
            "Total Reward =  11.822357955153956\n"
          ]
        }
      ]
    }
  ]
}